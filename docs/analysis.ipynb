{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_dir():\n",
    "    import os\n",
    "    from pathlib import Path\n",
    "    try:\n",
    "        return Path(__file__).parent.absolute()\n",
    "    except NameError:\n",
    "        return Path(os.getcwd())\n",
    "\n",
    "results = get_current_dir().parent / \"data\" / \"results.csv\"\n",
    "results_authors = get_current_dir().parent / \"data\" / \"results-authors.csv\"\n",
    "\n",
    "import pandas as pd\n",
    "actual = pd.read_csv(results)\n",
    "expected = pd.read_csv(results_authors)\n",
    "\n",
    "# hyperparameters from paper\n",
    "for alpha_ent in [0.30, 0.40]:\n",
    "    for alpha_word in [0.2, 0.3, 0.4, 0.5]:\n",
    "        for k in [20, 50, 100, 200]:\n",
    "            expected_row = expected[(expected[\"alpha_ent\"] == alpha_ent) & (expected[\"alpha_word\"] == alpha_word) & (expected[\"k\"] == k)]\n",
    "\n",
    "            expected_score_deezer = expected_row[\"score_deezer\"].values[0]\n",
    "            expected_score_score_itunes = expected_row[\"score_itunes\"].values[0]\n",
    "\n",
    "            # hyperparameters guessed by me\n",
    "            for n_topics in [10, 20, 50, 100]:\n",
    "                for n_neighbours in [5, 10, 20, 500]:\n",
    "                    actual_row = actual[(actual[\"alpha_ent\"] == alpha_ent) & (actual[\"alpha_word\"] == alpha_word) & (actual[\"k\"] == k) & (actual[\"n_topics\"] == n_topics) & (actual[\"n_neighbours\"] == n_neighbours)]\n",
    "\n",
    "                    actual_score_deezer = actual_row[\"score_deezer\"].values[0]\n",
    "                    actual_score_itunes = actual_row[\"score_itunes\"].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Results for Deezer Scores:\n",
      "T-test: statistic=0.22831692071150542, p-value=0.8194456338261875\n",
      "Confidence intervals (95.0%):\n",
      "\tActual: (51.994690848108995, 52.35325787987535)\n",
      "\tExpected: (51.89433108979605, 52.383164017836044)\n",
      "Variances:\n",
      "\tActual: 4.255412686851318\n",
      "\tExpected: 7.909005487126354\n",
      "KS-test: statistic=0.2035225048923679, p-value=1.1304443657367778e-09\n",
      "\n",
      "Results for iTunes Scores:\n",
      "T-test: statistic=14.412682128811188, p-value=5.31778508283801e-43\n",
      "Confidence intervals (95.0%):\n",
      "\tActual: (51.1179474752266, 51.406272094245026)\n",
      "\tExpected: (49.34592616094821, 49.71904448484436)\n",
      "Variances:\n",
      "\tActual: 2.7514677416295537\n",
      "\tExpected: 4.607805379686121\n",
      "KS-test: statistic=0.4520547945205479, p-value=2.055166401724473e-47\n",
      "iTunes Scores Statistics:\n",
      "Actual scores count: 511\n",
      "Non-null actual scores: 511\n",
      "Sample of actual scores: [51.6682, 51.369600000000005, 51.4062, 51.432599999999994, 52.913999999999994]\n"
     ]
    }
   ],
   "source": [
    "import scipy.stats as stats\n",
    "import numpy as np\n",
    "\n",
    "def perform_reproducibility_tests(actual_scores, expected_scores, metric_name, confidence_level=0.95):\n",
    "    t_stat, p_value = stats.ttest_ind(actual_scores, expected_scores)\n",
    "    \n",
    "    n_actual = len(actual_scores)\n",
    "    mean_actual = np.mean(actual_scores)\n",
    "    sem_actual = stats.sem(actual_scores)\n",
    "    ci_actual = stats.t.interval(confidence_level, n_actual-1, loc=mean_actual, scale=sem_actual)\n",
    "    \n",
    "    n_expected = len(expected_scores)\n",
    "    mean_expected = np.mean(expected_scores)\n",
    "    sem_expected = stats.sem(expected_scores)\n",
    "    ci_expected = stats.t.interval(confidence_level, n_expected-1, loc=mean_expected, scale=sem_expected)\n",
    "    \n",
    "    var_actual = np.var(actual_scores, ddof=1)\n",
    "    var_expected = np.var(expected_scores, ddof=1)\n",
    "    \n",
    "    ks_stat, ks_p = stats.ks_2samp(actual_scores, expected_scores)\n",
    "    \n",
    "    print(f\"\\nResults for {metric_name}:\")\n",
    "    print(f\"T-test: statistic={t_stat}, p-value={p_value}\")\n",
    "    print(f\"Confidence intervals ({confidence_level*100}%):\")\n",
    "    print(f\"\\tActual: ({ci_actual[0]}, {ci_actual[1]})\")\n",
    "    print(f\"\\tExpected: ({ci_expected[0]}, {ci_expected[1]})\")\n",
    "    print(f\"Variances:\")\n",
    "    print(f\"\\tActual: {var_actual}\")\n",
    "    print(f\"\\tExpected: {var_expected}\")\n",
    "    print(f\"KS-test: statistic={ks_stat}, p-value={ks_p}\")\n",
    "\n",
    "actual_deezer_scores = []\n",
    "actual_itunes_scores = []\n",
    "expected_deezer_scores = []\n",
    "expected_itunes_scores = []\n",
    "\n",
    "for alpha_ent in [0.30, 0.40]:\n",
    "    for alpha_word in [0.2, 0.3, 0.4, 0.5]:\n",
    "        for k in [20, 50, 100, 200]:\n",
    "            expected_row = expected[(expected[\"alpha_ent\"] == alpha_ent) & (expected[\"alpha_word\"] == alpha_word) & (expected[\"k\"] == k)]\n",
    "            \n",
    "            if expected_row.empty or expected_row[\"score_deezer\"].isnull().all() or expected_row[\"score_itunes\"].isnull().all():\n",
    "                continue\n",
    "\n",
    "            expected_score_deezer = expected_row[\"score_deezer\"].values[0]\n",
    "            expected_score_itunes = expected_row[\"score_itunes\"].values[0]\n",
    "            \n",
    "            for n_topics in [10, 20, 50, 100]:\n",
    "                for n_neighbours in [5, 10, 20, 500]:\n",
    "                    actual_row = actual[(actual[\"alpha_ent\"] == alpha_ent) & (actual[\"alpha_word\"] == alpha_word) & (actual[\"k\"] == k) & (actual[\"n_topics\"] == n_topics) & (actual[\"n_neighbours\"] == n_neighbours)]\n",
    "                    \n",
    "                    if actual_row.empty or actual_row[\"score_deezer\"].isnull().all() or actual_row[\"score_itunes\"].isnull().all():\n",
    "                        continue\n",
    "\n",
    "                    actual_score_deezer = actual_row[\"score_deezer\"].values[0]\n",
    "                    actual_score_itunes = actual_row[\"score_itunes\"].values[0]\n",
    "                    \n",
    "                    actual_deezer_scores.append(actual_score_deezer)\n",
    "                    actual_itunes_scores.append(actual_score_itunes)\n",
    "                    expected_deezer_scores.append(expected_score_deezer)\n",
    "                    expected_itunes_scores.append(expected_score_itunes)\n",
    "\n",
    "perform_reproducibility_tests(actual_deezer_scores, expected_deezer_scores, \"Deezer Scores\")\n",
    "perform_reproducibility_tests(actual_itunes_scores, expected_itunes_scores, \"iTunes Scores\")\n",
    "\n",
    "print(\"iTunes Scores Statistics:\")\n",
    "print(f\"Actual scores count: {len(actual_itunes_scores)}\")\n",
    "print(f\"Non-null actual scores: {sum(~np.isnan(actual_itunes_scores))}\")\n",
    "print(f\"Sample of actual scores: {actual_itunes_scores[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
